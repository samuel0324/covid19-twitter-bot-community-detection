{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xp6ZRImV_Mm2"
   },
   "source": [
    "# Detecting Twitter Bots in the Early COVID-19 Tweets\n",
    "\n",
    "# Data Collection\n",
    "\n",
    "### Samuel Park\n",
    "### October 25th, 2021\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QU746c-IDBkR"
   },
   "source": [
    "*Note that this notebook was run on a local machine. \n",
    "\n",
    "*Next notebook will be run on Google Colab primarily.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "to1lLczcQLm3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "# from twarc import Twarc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IImDaapsQLnR"
   },
   "source": [
    "\n",
    "\n",
    "## Coronavirus (covid19) Tweets - Early and Late April\n",
    "Dataset posted by [Shane Smith](https://www.kaggle.com/smid80/coronavirus-covid19-tweets-early-april) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ee09UbJDCaHP"
   },
   "source": [
    "The datset contains COVID-19-related tweets between March 29th and April 30th, 2020, when the pandemic was beginning in North America. The publisher had uploaded individual CSV file for each date between that timeframe. So, those CSV files have to be concantenated row-wise.\n",
    "\n",
    "When collecting COVID-19-related tweets, the publisher used these hashtags: \n",
    "- #coronavirus \n",
    "- #coronavirusoutbreak\n",
    "- #coronavirusPandemic, \n",
    "- #covid19\n",
    "- #covid_19\n",
    "- #epitwitter\n",
    "- #ihavecorona\n",
    "- #StayHomeStaySafe\n",
    "- #TestTraceIsolate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the code blocks below:\n",
    "1. Create a directory called `data` in current working directory\n",
    "2. Create a sub-directory called `shane_smith` in `data`\n",
    "3. Download all the CSV files to `shane_smith` from these two links:\n",
    "    - [Early April CSV files](https://www.kaggle.com/smid80/coronavirus-covid19-tweets-early-april)\n",
    "    - [Late April CSV files](https://www.kaggle.com/smid80/coronavirus-covid19-tweets-late-april)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the files are downloaded to `shane_smith`, run the code blocks below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate all the CSV files in `shane_smith` to one Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTlCoeL8QLnR",
    "outputId": "045c7638-875d-43f8-cc15-ed44e8c2dd04",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = 'data/shane_smith'\n",
    "\n",
    "# create a list of all the CSV files from Shane Smith\n",
    "all_files = [file for file in listdir(path)]\n",
    "all_files = sorted(all_files) # sort by date\n",
    "\n",
    "# store dataframe of each CSV file\n",
    "df_list = []\n",
    "\n",
    "# loop through the CSV files in data/shane_smith\n",
    "for filename in all_files:\n",
    "    # just to show progress\n",
    "    print(f'reading in {filename}')\n",
    "    \n",
    "    # read in the CSV file as a pandas dataframe\n",
    "    df_temp = pd.read_csv(f'data/shane_smith/{filename}', index_col=None, header=0)\n",
    "    \n",
    "    # append the dataframe to the list of dataframes to be concatenated later\n",
    "    df_list.append(df_temp)\n",
    "    print(f'appended dataframe of {filename} to df_list')\n",
    "\n",
    "# concatenate all the dataframes\n",
    "tweets = pd.concat(df_list, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xvFi-aCOQLnS",
    "outputId": "37280838-4119-44cc-a6ff-383936220661",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the consolidated dataframe as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DsHWvHVlQLnS"
   },
   "outputs": [],
   "source": [
    "# export the compiled df as csv file\n",
    "tweets.to_csv(path_or_buf='data/april_tweets_compiled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DbmTWCWWBskG"
   },
   "source": [
    "Preview the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qDctzg3tQLnS",
    "outputId": "91756801-2f14-4915-c370-8af9d9484620",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show the first 5 rows\n",
    "tweets.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the column types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RSskKMdGQLnS",
    "outputId": "84dcbd80-16b5-48ef-f998-20d0182ce77e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show data types of the columns\n",
    "tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ec0Rc_sNQLnT"
   },
   "source": [
    "`created_at` column should be in datetime format. `account_lang` is in `float64` format, but intuitively it should be in `object` format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HINenez2QLnT"
   },
   "source": [
    "Column descriptions:\n",
    "- status_id: unique id for each tweet\n",
    "- user_id: unique ide for a user\n",
    "- created_at: datetime for when the tweet was created\n",
    "- screen_name: user's Twitter handle\n",
    "- text: content of the tweet\n",
    "- source: link to the tweet\n",
    "- reply_to_status_id: tweet id to which this tweet is a reply\n",
    "- reply_to_user_id: user id to which this tweet is a reply\n",
    "- is_quote: whether or not this tweet is a quote\n",
    "- is_retweet: whether or not this tweet is a retweet\n",
    "- favourites_count: number of users who favorited this tweet\n",
    "- retweet_count: number of times this tweet was retweeted\n",
    "- country_code: two-letter code for countries\n",
    "- place_ful_name: full name of the place if geo-tagged (New York, NY)\n",
    "- place_type: urban or rural? Can be NaN if not geo-tagged\n",
    "- followers_count: number of followers this user has\n",
    "- friends_count: number of people this user follows\n",
    "- account_lang: the language setting of the user account\n",
    "- acount_created_at: the date when the account was created\n",
    "- verified: whether or not the user is verified (i.e., has blue check mark or not)\n",
    "- lang: the language of the tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIAUDg56QLnY"
   },
   "source": [
    "Let's get the unique language codes in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8tmsAfZQLnY",
    "outputId": "abe74ab8-21a5-46c9-f1b7-a1efa6b13d02",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tweets['lang'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5V85XOFQLnZ"
   },
   "source": [
    "As shown, there are many languages in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We want to narrow down our scope to English tweets only for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UhajzobMQLnZ"
   },
   "source": [
    "Let's only get the rows whose `lang` values are `en`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Adt7P4sSQLna",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# select rows whose lang is en\n",
    "tweets_en = tweets.loc[tweets['lang']=='en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W1pIpuzJQLna",
    "outputId": "cfcf83fc-0f90-4396-af6f-f98d5510a228",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_en.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_jRPXypQLnZ"
   },
   "source": [
    "It looks like there are 8,133,785 tweets whose language code is \"en\" (i.e., English)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OqfX5drRAgar"
   },
   "source": [
    "Export the English-only tweets as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "opdG5Ag0QLna"
   },
   "outputs": [],
   "source": [
    "tweets_en.to_csv('data/tweets_en_colab.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OikL1jlpQLna"
   },
   "source": [
    "`tweets_en` which includes only English tweets contains 8,133,785 rows (tweets) and 21 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7UoV8b7JAvrK"
   },
   "source": [
    "Data cleaning will be continued in the second notebook."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "capstone_samuel_park_notebook1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
